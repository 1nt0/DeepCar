{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import ntpath\n",
    "import cv2\n",
    "import random \n",
    "\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura en crudo del fichero CSV generado, añadiendo los labels a cada columna\n",
    "columnas = ['centro', 'izquierda', 'derecha', 'angulo', 'acelerador', 'freno', 'velocidad']\n",
    "datos = pd.read_csv('driving_log.csv', names = columnas)\n",
    "\n",
    "#Muestra en pantalla los 5 primeros elementos del fichero\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para obtener la 'hoja' del árbol perteneciente a la ruta absoluta de la imagen, que corresponde con su nombre\n",
    "def get_tail(path):\n",
    "  head, tail = ntpath.split(path) #Separando por \"/\", tail es el último elemento, y head todo lo anterior\n",
    "  return tail\n",
    "\n",
    "#Modificación de las 3 primeras columnas, correspondiente a la ruta de las imágenes\n",
    "datos['centro'] = datos['centro'].apply(get_tail)\n",
    "datos['izquierda'] = datos['izquierda'].apply(get_tail)\n",
    "datos['derecha'] = datos['derecha'].apply(get_tail)\n",
    "\n",
    "#Muestra en pantalla los 5 primeros elementos del fichero, con las rutas ya procesadas\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definición de las características del histograma\n",
    "num_bins = 23\n",
    "max_muestras_por_bin = 300\n",
    "\n",
    "#Generación del histograma (sus variables serán usadas en la celda siguiente para procesar los elementos sobrantes)\n",
    "hist, bins = np.histogram(datos['angulo'], num_bins)\n",
    "\n",
    "#Dibujado del histograma\n",
    "plt.hist(datos['angulo'], num_bins)\n",
    "\n",
    "plt.xlabel('Ángulo')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title(\"Distribución de los ángulos\") \n",
    "\n",
    "#Línea representando max_muestras_por_bin sobre el histograma\n",
    "plt.plot((np.min(datos['angulo']), np.max(datos['angulo'])), (max_muestras_por_bin, max_muestras_por_bin))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------BALANCEO DEL DATASET------------------------\n",
    "\n",
    "datos_preprocesados = datos.copy() #Copia del dataset original\n",
    "elementos_a_eliminar = []\n",
    "\n",
    "#Recorrido de cada bin\n",
    "for i in range(num_bins):\n",
    "  lista = []\n",
    "#Recorrido de cada elemento del dataset: si el ángulo pertenece al bin que estamos recorriendo, lo \n",
    "#metemos en la lista\n",
    "  for j in range(len(datos['angulo'])):\n",
    "    if datos['angulo'][j] >= bins[i] and datos['angulo'][j] <= bins[i+1]:\n",
    "      lista.append(j)\n",
    "    \n",
    "#Mezclamos los elementos que pertenecen al bin\n",
    "  lista = shuffle(lista)\n",
    "  #Nos quedamos con las \"sobras\" basado en el umbral que hayamos decidido (max_muestras_por_bin), para posteriormente\n",
    "  #añadirlo a elementos_a_eliminar y utilizarla como lista con los elementos a eliminar en el dataset\n",
    "  lista = lista[max_muestras_por_bin:]\n",
    "  elementos_a_eliminar.extend(lista)\n",
    "\n",
    "#Eliminamos dichos datos del dataset\n",
    "datos_preprocesados.drop(datos_preprocesados.index[elementos_a_eliminar], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Representación del histograma del dataset una vez procesado\n",
    "plt.hist(datos_preprocesados['angulo'], num_bins)\n",
    "\n",
    "plt.xlabel('Ángulo')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title(\"Distribución de los ángulos\")\n",
    "\n",
    "#Línea representando max_muestras_por_bin sobre el histograma\n",
    "plt.plot((np.min(datos_preprocesados['angulo']), np.max(datos_preprocesados['angulo'])), \n",
    "         (max_muestras_por_bin, max_muestras_por_bin))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de recortado de un fotograma\n",
    "def recorte(img):\n",
    "    img = img[70:135,:,:]\n",
    "    return img\n",
    "\n",
    "#Lectura del fotograma de prueba (fotograma_prueba.jpg debe encontrarse en la misma carpeta que este notebook)\n",
    "imagen_original = mpimg.imread('fotograma_prueba.jpg')\n",
    "\n",
    "#Uso de la función recorte para recortar el fotograma\n",
    "imagen_recortada = recorte(imagen_original) \n",
    "\n",
    "#Generación conjunta de las imágenes para su comparación\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.tight_layout()\n",
    "\n",
    "axs[0].imshow(imagen_original)\n",
    "axs[0].set_title('Imagen original')\n",
    "axs[1].imshow(imagen_recortada)\n",
    "axs[1].set_title('Imagen recortada')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtención de las imágenes y sus ángulos del dataset\n",
    "def get_imgs_y_angulos(datos):\n",
    "    imagenes = []\n",
    "    angulos = []\n",
    "    for i in range(len(datos)):\n",
    "        elemento = datos.iloc[i]\n",
    "        \n",
    "        angulo = elemento[3]\n",
    "        \n",
    "        #Imagen central\n",
    "        imagen_centro = elemento[0]\n",
    "        imagenes.append(os.path.join('IMG/', imagen_centro))\n",
    "        angulos.append(angulo)\n",
    "        \n",
    "        #Imagen izquierda\n",
    "        imagen_izquierda = elemento[1]\n",
    "        imagenes.append(os.path.join('IMG/', imagen_izquierda))\n",
    "        angulos.append(angulo + 0.2)\n",
    "        \n",
    "        #Imagen derecha\n",
    "        imagen_derecha = elemento[2]\n",
    "        imagenes.append(os.path.join('IMG/', imagen_derecha))\n",
    "        angulos.append(angulo - 0.2)\n",
    "        \n",
    "    imagenes = np.asarray(imagenes)\n",
    "    angulos = np.asarray(angulos)\n",
    "    \n",
    "    return imagenes, angulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes, angulos = get_imgs_y_angulos(datos_preprocesados)\n",
    "print(\"Número de imágenes:\", len(imagenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#División del dataset en conjuntos de entrenamiento y prueba\n",
    "x_entrenamiento, x_test, y_entrenamiento, y_test = train_test_split(imagenes, angulos, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogramas comparativos de los elementos \"etiquetas\" (y_, ángulos de dirección) en los dos conjuntos creados\n",
    "fig, ejes = plt.subplots(1,2, figsize=(12,4))\n",
    "\n",
    "ejes[0].hist(y_entrenamiento, bins=num_bins, width=0.05, color='blue')\n",
    "ejes[0].set_title('Subconjunto y_entrenamiento')\n",
    "ejes[0].set_xlabel('Ángulo')\n",
    "ejes[0].set_ylabel('Frecuencia')\n",
    "\n",
    "ejes[1].hist(y_test, bins=num_bins, width=0.05, color='red')\n",
    "ejes[1].set_title('Subconjunto y_test')\n",
    "ejes[1].set_xlabel('Ángulo')\n",
    "ejes[1].set_ylabel('Frecuencia')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iluminacion(img):\n",
    "    iluminacion = iaa.Multiply((0.2, 1.3))\n",
    "    img = iluminacion.augment_image(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def zooming(img):\n",
    "    zooming = iaa.Affine(scale={\"x\": (1.0, 1.4), \"y\": (1.0, 1.4)})\n",
    "    img = zooming.augment_image(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def desplazamiento(img):\n",
    "    desplazamiento = iaa.Affine(translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)})\n",
    "    img = desplazamiento.augment_image(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def volteo(img, angulo):\n",
    "    volteo = iaa.Fliplr(1.0)\n",
    "    img = volteo.augment_image(img)\n",
    "    angulo = -angulo\n",
    "    \n",
    "    return img, angulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aumento_aleatorio(img, angulo):\n",
    "    img = mpimg.imread(img)\n",
    "    \n",
    "    if np.random.random_sample() < 0.5:\n",
    "        img = iluminacion(img)\n",
    "        \n",
    "    if np.random.random_sample() < 0.5:\n",
    "        img = zooming(img)\n",
    "        \n",
    "    if np.random.random_sample() < 0.5:\n",
    "        img = desplazamiento(img)\n",
    "        \n",
    "    if np.random.random_sample() < 0.5:\n",
    "        img, angulo = volteo(img, angulo)\n",
    "    \n",
    "    return img, angulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_original = mpimg.imread('fotograma_prueba.jpg')\n",
    "# img_zooming = zooming(img_original)\n",
    "# img_desplazada = desplazamiento(img_original)\n",
    "# img_iluminada = iluminacion(img_original)\n",
    "# img_volteada, _ = volteo(img_original, 0)\n",
    "\n",
    "# fig, ejes = plt.subplots(1,2, figsize=(13,5))\n",
    "\n",
    "# ejes[0].imshow(img_original)\n",
    "# ejes[0].set_title('Imagen original')\n",
    "# ejes[1].imshow(img_volteada)\n",
    "# ejes[1].set_title('Imagen volteada horizontalmente')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----CONJUNTO DE FUNCIONES PARA EL PREPROCESAMIENTO DE IMÁGENES----\n",
    "def recorte(img):\n",
    "    img = img[70:135,:,:] \n",
    "    return img\n",
    "\n",
    "def RGBaYUV(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV) \n",
    "    return img\n",
    "\n",
    "def RGBaGRAY(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return img\n",
    "\n",
    "def redimensionar_imagen(img, x, y):\n",
    "    img = cv2.resize(img, (x, y))\n",
    "    return img\n",
    "\n",
    "def normalizar_imagen(img):\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de preprocesamiento de imágenes para el modelo de LeNet-5\n",
    "def img_preproceso_lenet5(img):\n",
    "    \n",
    "    img = recorte(img)\n",
    "    img = RGBaGRAY(img)\n",
    "    img = redimensionar_imagen(img, 32, 32)\n",
    "    img = img[:, :, np.newaxis]\n",
    "    img = normalizar_imagen(img)\n",
    "    return img\n",
    "\n",
    "#Función de preprocesamiento de imágenes para el modelo de NVIDIA\n",
    "def img_preproceso_nvidia(img):\n",
    "    \n",
    "    img = recorte(img)\n",
    "    img = RGBaYUV(img)\n",
    "    img = redimensionar_imagen(img, 200, 66)\n",
    "    img = normalizar_imagen(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(imgs, angulos, batch_size, modo):\n",
    "    \n",
    "    while True:\n",
    "        batch_imgs = []\n",
    "        batch_angulos = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            #Número aleatorio que actuará de índice para el conjunto de imágenes\n",
    "            num_aleatorio = random.randint(0, len(imgs)-1)\n",
    "            \n",
    "            if modo == 'entrenamiento':\n",
    "                img, angulo = aumento_aleatorio(imgs[num_aleatorio], angulos[num_aleatorio])\n",
    "                \n",
    "            else:\n",
    "                img = mpimg.imread(imgs[num_aleatorio])\n",
    "                angulo = angulos[num_aleatorio]\n",
    "            \n",
    "            img = img_preproceso_nvidia(img) #CAMBIAR en función del modelo neuronal usado\n",
    "            batch_imgs.append(img) \n",
    "            batch_angulos.append(angulo)\n",
    "            \n",
    "        yield(np.asarray(batch_imgs), np.asarray(batch_angulos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamiento de todas las imágenes de los subconjuntos x_entrenamiento y x_test \n",
    "\n",
    "#ESTE PROCESAMIENTO PASA AHORA A REALIZARSE DENTRO DEL GENERATOR\n",
    "\n",
    "#Procesamiento para el modelo LeNet-5\n",
    "# x_entrenamiento = np.array([img_preproceso_lenet5(x) for x in x_entrenamiento])\n",
    "# x_test = np.array([img_preproceso_lenet5(x) for x in x_test])\n",
    "\n",
    "#Procesamiento para el modelo NVIDIA\n",
    "# x_entrenamiento = np.array([img_preproceso_nvidia(x) for x in x_entrenamiento])\n",
    "# x_test = np.array([img_preproceso_nvidia(x) for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, Convolution2D, MaxPooling2D, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_lenet5():\n",
    "    modelo = Sequential()\n",
    "\n",
    "    modelo.add(Conv2D(6, (5, 5), activation='elu', input_shape=(32, 32, 1)))\n",
    "    modelo.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    modelo.add(Conv2D(16, (5, 5), activation='elu'))\n",
    "    modelo.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    modelo.add(Conv2D(120, (5, 5), activation='elu'))\n",
    "    \n",
    "    modelo.add(Flatten())\n",
    "\n",
    "    modelo.add(Dense(84, activation='elu'))\n",
    "\n",
    "    modelo.add(Dense(1))\n",
    "    \n",
    "    optimizador = Adam(lr=1e-3)\n",
    "    modelo.compile(loss='mse', optimizer=optimizador)\n",
    "    \n",
    "    return modelo\n",
    "\n",
    "def modelo_nvidia():\n",
    "    modelo = Sequential()\n",
    "    \n",
    "    modelo.add(Conv2D(24, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
    "    modelo.add(Conv2D(36, (5, 5), strides=(2, 2), activation='elu'))\n",
    "    modelo.add(Conv2D(48, (5, 5), strides=(2, 2), activation='elu'))\n",
    "    modelo.add(Conv2D(64, (3, 3), activation='elu'))\n",
    "    modelo.add(Conv2D(64, (3, 3), activation='elu'))\n",
    "    \n",
    "    modelo.add(Flatten())\n",
    "    \n",
    "    modelo.add(Dense(100, activation='elu'))\n",
    "    modelo.add(Dense(50, activation='elu'))\n",
    "    modelo.add(Dense(10, activation='elu'))\n",
    "    modelo.add(Dense(1))\n",
    "    \n",
    "    optimizador = Adam(lr=1e-3)\n",
    "    modelo.compile(loss='mse', optimizer=optimizador)\n",
    "    \n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación y resumen del modelos neuronal de LeNet-5 creado\n",
    "modelo_lenet = modelo_lenet5()\n",
    "print(modelo_lenet.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación y resumen del modelo neuronal de NVIDIA creado\n",
    "modelo_nvidia = modelo_nvidia()\n",
    "print(modelo_nvidia.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LECTURA DE MODELOS EXPORTADOS\n",
    "modelo_lenet = load_model('modelo_lenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENTRENAMIENTO DEL MODELO DE LENET-5\n",
    "#---Hay que haber preprocesado las imágenes con la función img_preproceso_lenet5 en el batch_generator. \n",
    "#---En caso de haberlo hecho con img_preproceso_nvidia, hay que reiniciar el kernel y volverlo a ejecutar\n",
    "#---con la función adecuada.\n",
    "entrenamiento_lenet = modelo_lenet.fit_generator(batch_generator(x_entrenamiento, y_entrenamiento, 100, 'entrenamiento'), \n",
    "                                                   steps_per_epoch=200, \n",
    "                                                   epochs=10, \n",
    "                                                   validation_data=batch_generator(x_test, y_test, 100, ''),\n",
    "                                                   validation_steps=200, \n",
    "                                                   verbose=1, \n",
    "                                                   shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Representación de los valores de LOSS por cada época en el modelo de LeNet-5 entrenado\n",
    "plt.plot(entrenamiento_lenet.history['loss'])\n",
    "plt.plot(entrenamiento_lenet.history['val_loss'])\n",
    "\n",
    "plt.legend(['Entrenamiento', 'Validación'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Época')\n",
    "\n",
    "#print(entrenamiento_lenet.history['val_loss'][39] - entrenamiento_lenet.history['loss'][39])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lenet.save(\"modelo_lenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENTRENAMIENTO DEL MODELO DE NVIDIA\n",
    "#---Hay que haber preprocesado las imágenes con la función img_preproceso_nvidia en el batch_generator. \n",
    "#---En caso de haberlo hecho con img_preproceso_lenet5, hay que reiniciar el kernel y volverlo a ejecutar\n",
    "#---con la función adecuada.\n",
    "#entrenamiento_nvidia = modelo_nvidia.fit(x_entrenamiento, y_entrenamiento, epochs=40, validation_data=(x_test, y_test), \n",
    "#                       batch_size=100, verbose=1, shuffle=1)\n",
    "\n",
    "entrenamiento_nvidia = modelo_nvidia.fit_generator(batch_generator(x_entrenamiento, y_entrenamiento, 100, 'entrenamiento'), \n",
    "                                                   steps_per_epoch=300, \n",
    "                                                   epochs=10, \n",
    "                                                   validation_data=batch_generator(x_test, y_test, 100, ''),\n",
    "                                                   validation_steps=200, \n",
    "                                                   verbose=1, \n",
    "                                                   shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Representación de los valores de LOSS por cada época en el modelo de NVIDIA entrenado\n",
    "plt.plot(entrenamiento_nvidia.history['loss'])\n",
    "plt.plot(entrenamiento_nvidia.history['val_loss'])\n",
    "\n",
    "plt.legend(['Entrenamiento', 'Validación'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Época')\n",
    "\n",
    "plt.show()\n",
    "#print(entrenamiento_nvidia.history['val_loss'][9] - entrenamiento_nvidia.history['loss'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_nvidia.save(\"modelo_nvidia.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
